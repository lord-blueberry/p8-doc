\section{Alternatives to the Major Cycle}\label{killmajor}
Many Compressed Sensing reconstructions use the Major Cycle architecture\cite{girard2015sparse, dabbech2018cygnus, mcewen2011compressed, pratley2018fast}  and do not discuss alternatives. Pratley et al\cite{pratley2017robust} optimized the non-uniform FFT in the context of Compressed Sensing reconstructions. Dabbech et al.\cite{dabbech2017wEffect} investigated $w$-term approximations for reducing runtime costs of Compressed Sensing reconstructions.

Although Compressed Sensing algorithms produce higher quality reconstructions, the CLEAN algorithm so far has lower runtime costs. Both use a version of the Major Cycle architecture for efficient transformation of Visibilities to image space, and to correct the effects of wide field of view imaging. This project explores three different ways of calculating the Fourier transform which leads to three different architectures. In this section we discuss the merits of each alternative in the context of reducing the cost for MeerKAT reconstructions.

\subsection{Optimal projection on a uniform grid}
In each iteration, the Major Cycle reduces the error from both, the non-uniform FFT approximation, and from incomplete measurements. Here, we discuss the potentials and problems of separating the problem into two optimization objectives \eqref{killmajor:sep:major} \eqref{killmajor:sep:deconv} and solve each after the other. This architecture first uses the optimal projection on a uniformly sampled grid, which is several times smaller than the original Visibility measurements.

\begin{alignat}{1}
\underset{I_{dirty}}{minimize} \:& \left \|  V - \tilde{F}I_{dirty} \right \|_2^2\label{killmajor:sep:major}\\
\underset{x}{minimize} \:& \left \| I_{dirty} - x \star PSF \right \|_2^2 + \lambda \left \| P(x) \right \|_1 \label{killmajor:sep:deconv}
\end{alignat}


The first objective \eqref{killmajor:sep:major} solves for the optimal projection on a uniform grid. Like the Major Cycle, it uses the non-uniform FFT to find the optimal projection, but we only minimize the error of the non-uniform FFT. Here, we may be able to use specialized algorithms to use as few iterations as possible. After we found the optimal projection, we only need the dirty image for further processing. The objective \eqref{killmajor:sep:deconv} only needs the dirty image and the Point Spread Function to find the observed image according to some prior $P()$.

In practice, the $PSF$ of objective \eqref{killmajor:sep:deconv} is difficult to represent on a uniform grid. The $PSF$ varies over the image. For the most accurate result, we would need a $PSF$ for each pixel. The naive way to calculate a $PSF$ for a pixel is to set all amplitudes of our Visibilities to 1, shift the phase to the desired pixel, and calculate the Fourier Transform. The naive way to calculate a $PSF$ for each pixel leads to a quadratic runtime.

CLEAN gets away with a constant $PSF$\footnote{CLEAN implementations in Radio Astronomy typically use a constant $PSF$. This is not necessary, one can also implement CLEAN with a varying $PSF$.}, because of the Major Cycle architecture. In each cycle, it can reduce the error it introduced in the previous cycle, leading to a more accurate reconstruction. In the new architecture, we need several $PSF$s for a comparable accuracy to the Major Cycle, and this number dictates whether we can reduce the runtime costs. The question, how many $PSF$s are necessary, seems currently unknown in the Radio Astronomy community, as it becomes irrelevant for the Major Cycle. As of the time of writing, we do not know of any published research into this area. We do not have good estimates on the viability of this architecture.

The main advantage for this architecture is that it reduces the problem to a uniformly-sampled grid, and ignore the original Visibilities in later steps. However, in the context of self-calibration, we cannot ignore the non-uniformly sampled Visibilities. We need a transformation from the image back to the original Visibilities and improve the calibration parameters. Self-calibration negates the main advantage of the architecture. Unless we find a way to map the Visibilities together with their calibration parameters on a uniformly-sampled grid, this architecture does not seem practical for MeerKAT.


\subsection{Spherical Harmonics}
Spherical Harmonics are a different way to represent the measurements of an interferometer. Carozzi\cite{carozzi2015imaging} derived a measurement equation based on the fact that the Visibilities fulfils the Helmholtz equation. In practical terms, Carozzi showed we can replace the non-uniform FFT with the Spherical Harmonics Transform in the Major Cycle architecture. Although the Spherical Harmonics Transform has interesting properties for full-sky imaging, this change alone neither leads to a different architecture, nor to a runtime improvement\footnote{The fast Spherical Harmonics Transform is a generalization of the non-uniform FFT\cite{kunisnonequispaced} and is still an active field of research\cite{schaeffer2013efficient}.}

Compared to the Fourier domain, Spherical Harmonics naturally represent wide field of view interferometers and do not have a third dimension. This opens up new designs for Compressed Sensing reconstructions. For example, we can reconstruct the image by in-painting the missing Spherical Harmonics. Because they naturally represent curved surfaces, we can in-paint in a two dimensional space instead of three. Another direction is to image on the sphere directly. MCewen et al.\cite{mcewen2008simulating} showed a way to put two dimensional wavelets on the sphere. A Compressed Sensing reconstruction can use a spherical wavelet as regularization and may simplify the transformation between measurements and reconstruction space.

Sadly, there is little published research in this area for Radio Astronomy image reconstructions. MCewen et al.\cite{mcewen2008simulating} improved the runtime costs of simulations with the spherical Haar wavelet. Later work\cite{mcewen2011compressed} showed a proof-of-concept Compressed Sensing reconstruction projected on the sphere, which improved the image quality. However, it did not use Spherical Harmonics and \cite{mcewen2011compressed} is still based on the Fourier transform. At this point we have not found a proof-of-concept reconstruction algorithm which uses Spherical Harmonics to reduce runtime costs. 

Although there seems untapped potential for new, cheaper reconstruction algorithms with Spherical Harmonics, practical limitations may explain the lack of research in this area. The Fourier relationship, Calibration, the effect of the ionosphere, everything discussed in section \ref{meerkat} is based on a plane wave arriving at the instrument\cite{thompson1986interferometry, smirnov2011revisiting}. Spherical Harmonics are not. They are derived from a different property of the signal. The plane wave formalism may not translate to Spherical Harmonics. We may need to re-invent self-calibration, ionosphere distortion and more for Spherical Harmonic reconstructions.


\subsection{Direct Fourier Transform}
Hardy\cite{hardy2013direct} replaced the non-uniform FFT with the direct Fourier Transform. It leads to a simplified architecture which naturally handles the $w$-term, but the whole Fourier matrix $F$ has to be kept in memory. Using the direct Fourier Transform simplifies the architecture of the reconstruction. The drawback is either a large memory requirement for caching, or high runtime costs for continually calculating the transform matrix. For MeerKAT reconstructions where we reconstruct millions of pixels from several billions of Visibilities, the matrix becomes too large for any practical application.

However, the full Fourier matrix is not needed. Remember that CLEAN assumes the image is sparse, meaning only a few pixels are non-zero. In practice, even with extended emissions in the image, large regions of pixels are zero. They do not contribute to the reconstruction. Other Compressed Sensing reconstructions showed that the reconstructed image can be more sparsely represented in an over-complete wavelet basis. Girard et al.\cite{girard2015sparse} used the over-complete starlet transform, and Dabbech et al.\cite{dabbech2018cygnus} represent the image in several Daubechies frames. In a sparse reconstruction space, we only need to calculate the direct Fourier Transform for non-zero components of our basis, reducing the memory and runtime costs of the direct Fourier Transform.

In this project, we leverage the starlet transform and create an algorithm which uses the direct Fourier Transform for a few non-zero starlet components.