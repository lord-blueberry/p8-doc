\section{Alternatives to the non-uniform FFT}\label{killmajor}
The MeerKAT creates wide field of View observations. For accurate image reconstruction, the algorithm also has to optimize the calibration parameters $C$ together with the observed image $x$. This leads us to the following optimization objective \eqref{killmajor:objective} for MeerKAT imaging. $F_{wof}$ represents the wide field of view Fourier Transform with three dimensional Visibilities and two dimensional image. 

\begin{equation}\label{killmajor:objective}
\underset{C, x}{minimize} \: \left \| CV - F_{wof}x \right \|_2^2 + \lambda \left \| P(x) \right \|_1
\end{equation}

State of the art CLEAN algorithms use the Major Cycle architecture for image reconstruction. They use the $w$-stacking algorithm to approximate $F_{wof}$ and cycle between Visibility and image space. Current Compressed Sensing approaches use the $w$-stacking algorithm in a similar manner\cite{girard2015sparse, dabbech2018cygnus, mcewen2011compressed, pratley2018fast}, but need more cycles to converge to an image. This is one reason for the overall higher runtime costs of Compressed Sensing. Various research focuses on improving the reconstructions in the context of the non-uniform FFT and $w$-stacking. Pratley et al\cite{pratley2017robust} optimized the accuracy of the non-uniform FFT for Compressed Sensing reconstructions. Dabbech et al.\cite{dabbech2017wEffect} investigated $w$-term approximations for reducing runtime costs. 

Alternatives to the non-uniform FFT are rarely discussed in Radio Astronomy. We found only Hardy\cite{hardy2013direct} which investigated the direct Fourier Transform for Compressed Sensing reconstructions. In this project, we investigate if we can use an alternative to the non-uniform FFT and reduce the runtime costs of Compressed Sensing. We discuss three alternatives: Optimal projection on a uniform grid, Spherical Harmonics and the direct Fourier Transform.

\subsection{Optimal projection on a uniform grid}
The $w$-stacking algorithm continually cycles between non-uniform Visibility space and uniform image space. Over several cycles a reconstruction algorithm finds the optimal projection on the uniform grid together with the observed image. Here we discuss the potential of searching for the optimal projection first and reconstruct the image in a second step.

\begin{alignat}{1}
\underset{I_{dirty}}{minimize} \:& \left \|  V - \tilde{F_{wof}}I_{dirty} \right \|_2^2\label{killmajor:sep:major}\\
\underset{x}{minimize} \:& \left \| I_{dirty} - x \star PSF \right \|_2^2 + \lambda \left \| P(x) \right \|_1 \label{killmajor:sep:deconv}
\end{alignat}


The first objective \eqref{killmajor:sep:major} solves for the optimal projection on a uniform grid. It uses the $w$-stacking algorithm, represented as $\tilde{F_{wof}}$, which approximates the wide field of view Fourier transform. After we found the optimal projection, we do not need the original Measurements for further processing. The objective \eqref{killmajor:sep:deconv} only needs the dirty image and the Point Spread Function to find the observed image according to some prior $P()$. In this setting, Compressed Sensing reconstructions and CLEAN need the same amount of $w$-stacking cycles.  \eqref{killmajor:sep:major}. 

The main advantage for this architecture is that it reduces the problem to a uniformly-sampled grid, and ignore the original Visibilities in later steps. However, note that \eqref{killmajor:sep:major} and \eqref{killmajor:sep:deconv} do not solve for calibration parameters. $C$ is defined in the non-uniformly sampled space. Unless we find a way to project the calibration problem on a uniform grid too, we cannot ignore the original Visibilities and the main advantage of this setting vanishes. 

In practice, there is a second difficulty with the optimal projection: The $PSF$ of objective \eqref{killmajor:sep:deconv} is difficult to represent accurately on a uniform grid. It varies for each pixel, the $PSF$ at the center of the dirty image is not identical to the $PSF$ for edge pixels. For the most accurate result, we would need a $PSF$ for each pixel. The naive way to calculate a $PSF$ for a pixel is to set all amplitudes of our Visibilities to 1, shift the phase to the desired pixel, and calculate the Fourier Transform. The naive way to calculate a $PSF$ for each pixel leads to a quadratic runtime.

CLEAN gets away with a constant $PSF$\footnote{CLEAN implementations in Radio Astronomy typically use a constant $PSF$. This is not necessary, one can also implement CLEAN with a varying $PSF$.}, because of the Major Cycle architecture. In each cycle, it reduces the error it introduced by the constant $PSF$ of the previous cycle, leading to a more accurate reconstruction. When we project on a uniformly sampled grid, we need several $PSF$s for a comparable accuracy to the Major Cycle, and this number dictates whether we can reduce the runtime costs. The question, how many $PSF$s are necessary, seems currently unknown in the Radio Astronomy community, as it becomes irrelevant in the Major Cycle architecture.






Solving for the Calibration parameters $C$ of our reconstruction problem \eqref{killmajor:objective} destroys the main advantage of the projection. 


\subsection{Spherical Harmonics}
Spherical Harmonics are a different way to represent the measurements of an interferometer. Carozzi\cite{carozzi2015imaging} derived a measurement equation based on the fact that the Visibilities fulfils the Helmholtz equation. In practical terms, Carozzi showed we can replace $F_{wof}$ in our reconstruction problem \eqref{killmajor:objective} the Spherical Harmonics Transform. 

Compared to the Fourier domain, Spherical Harmonics naturally represent wide field of view interferometers and do not have a third dimension. This opens up new designs for Compressed Sensing reconstructions. For example, we can reconstruct the image by in-painting the missing Spherical Harmonics. Because they naturally represent curved surfaces, we can in-paint in a two dimensional space instead of three. Another direction is to image on the sphere directly. MCewen et al.\cite{mcewen2008simulating} showed a way to put two dimensional wavelets on the sphere. A Compressed Sensing reconstruction can use a spherical wavelet as regularization and may simplify the transformation between measurements and reconstruction space.

Sadly, there is little published research in this area for Radio Astronomy image reconstructions. MCewen et al.\cite{mcewen2008simulating} improved the runtime costs of simulations with the spherical Haar wavelet. Later work\cite{mcewen2011compressed} showed a proof-of-concept Compressed Sensing reconstruction projected on the sphere, which improved the image quality. However, it did not use Spherical Harmonics and \cite{mcewen2011compressed} is still based on the Fourier transform. At this point we have not found a proof-of-concept reconstruction algorithm which uses Spherical Harmonics to reduce runtime costs. 

There seems untapped potential for new, cheaper reconstruction algorithms with Spherical Harmonics. But replacing the $F_{wof}$ with the Spherical Harmonics Transform might have wide-ranging consequences. The Fourier relationship, self-calibration, the effect of the ionosphere, everything discussed in section \ref{meerkat} is based on a plane wave arriving at the instrument\cite{thompson1986interferometry, smirnov2011revisiting}. Spherical Harmonics are not. They are derived from a different property of the signal. If we use the Spherical Harmonics Transform, we do not know if we can still solve for the calibration parameters $C$ in \eqref{killmajor:objective}. We may need to re-invent self-calibration, ionosphere distortion and more for Spherical Harmonic reconstructions.


\subsection{Direct Fourier Transform}
The direct Fourier Transform replaces the $w$-stacking algorithm with the full, explicit Fourier Matrix $F_{wof}$. Hardy\cite{hardy2013direct} showed the direct Fourier Transform leads to a simplified reconstruction algorithm which simplifies parallel computing. In this setting, we can calculate the exact wide field of view Fourier Transform from image to Visibility space, and can solve for the calibration parameters with any intermediate reconstruction image. The downside is of course we need the whole matrix $F_{wof}$ either in memory, or need to re-calculate it on the fly. For MeerKAT reconstructions, where we reconstruct millions of pixels from several billions of Visibilities, the matrix becomes too large for any practical application.

However, the full matrix is not needed. Remember that CLEAN assumes the image is sparse, meaning only a few pixels are non-zero. In practice, even with extended emissions in the image, large regions of pixels are zero. They do not contribute to the reconstruction. We only need to calculate the Transform for non-zero components. With Compressed Sensing, we are not required to reconstruct in the image space. We can use a space where the image can be represented in even fewer non-zero components, reducing the memory requirement and runtime costs of the direct Fourier Transform. In this project, we use starlets as sparse image representation. We investigate if this approach is enough to let the direct Fourier Transform scale to MeerKATs data volume. 

