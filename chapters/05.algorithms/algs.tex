\section{Compressed Sensing with direct Fourier Transform\\ and Coordinate Descent}\label{cd}
Instead of using the Major Cycle architecture and approximate the non-uniform FFT approximation, we directly use the Fourier transform matrix $F$. We show the principle of our approach and of Compressed Sensing reconstructions in general at a simplified example. Let us minimize the objective function \eqref{cd:clean}.

\begin{equation}\label{cd:clean}
\underset{x}{minimize} \: \left \| V - Fx \right \|_2^2 + \lambda \left \| x \right \|_1 \\
\end{equation}

The data term $\left \| V - F^{-1}x \right \|_2^2$ forces our image to be similar to the measurements, and the regularization term $\left \| x \right \|_1$ tells us how likely the current reconstruction is to be the true image. The parameter $\lambda$ weights the trade-off between the data and the regularization term. With our term we assume our image contains only a limited number of non-zero pixels.  When the instrument observes stars, they take up a single pixel in the image. In this case, our prior models the true image well, and the theory of compressed sensing states we are virtually guaranteed to find the truly observed image at the minimum of our objective function \eqref{cd:clean}.

We can use a number of different optimization algorithms to optimize \eqref{cd:clean}. Note however in the one dimensional case, where we only have one pixel, the data term of the objective \eqref{cd:clean} forms a parabola and the regularization term a shrink operation\footnote{The shrink operation reduces the magnitude of the pixel by $\lambda$. For example: Pixel $x = -12.4$, $\lambda = 0.6$. The new pixel value after shrinkage follows as $shrink(-12.4, 0.6) = -11.9$}. The optimum for a single pixel can be calculated by solving for the minimum of the parabola first, followed by a shrink operation. With Coordinate Descent we can exploit this property. We fix all pixels except for one and iteratively solve for the current minimum of each pixel. Now when we iterate over all pixels several times, we eventually converge to a solution. The full Coordinate Descent algorithm can be implemented in a few lines of python code:

\begin{lstlisting} 
def coordinate_descent(V_residual, x, lambda, max_iter):
	for k in range(0, max_iter):
		for i in pixels_row:
			for j in pixels_column:
				x_old = x[i, j]
				fourier_column = calculate_fourier_transform(i, j)
				fr = real(fourier_column)
				fi = imag(fourier_column)
				rr = real(V_residual)
				ri = imag(V_residual)
				
				#find apex
				a = sum(fr**2 + 2*fr*fi + fi**2)
				b = sum(fr*rr + fr*ri + fi*rr + fi*ri)
				x_new = b / a + x_old
				
				x_new = shrink(x_new, lambda)
				x[i, j] = x_new
				V_residual = V_residual - fourier_column * (x_new - x_old)
\end{lstlisting}\label{cd:basic}

Coordinate Descent has to iterate over every pixels possibly several times. How quickly Coordinate Descent converges in theory is not well understood. Our optimization function \eqref{cd:clean} falls in the class of quadratic programming with a strictly convex objective. In this case, Coordinate Descent is guaranteed to converge at least linearly\cite{luo1992convergence}. Sadly, real-world objective functions for image reconstruction are often not strictly convex. Usually our image is constrained to have only positive pixels\cite{mcewen2011compressed}, which breaks the strictly convex property of the objective function. In our environment, the convergence guarantees of Coordinate Descent are not well understood in theory.

In practice, Coordinate Descent can be improved with heuristics. Since we assume our image contains only a few stars, a few non-zero pixels, the simple Coordinate Descent algorithm wastes resources checking if the pixel is still zero. A better scheme would be the active set heuristic\cite{friedman2010regularization}: We iterate over every pixel once. Then, for a given number of iterations, we only check the pixels that have changed. This is an improvement, but too expensive in the context of MeerKAT. A reconstruction problem can have billions of Visibilities and serveral millions of pixels. Since $F$ has the size of Visibilities times pixels, it gets too expensive to calculate all columns even once.

However, it turns out we do not need to if we imitate CLEAN: For CLEAN, the non-uniform FFT approximates the 'dirty' image, which is corrupted by the effects of incomplete measurements. CLEAN then subtracts a fraction of the PSF at the largest pixel value. In other words, the largest pixel value in the dirty image is the most likely non-zero pixel. We can use the dirty image approximation for a 'probability distribution' of non-zero pixels. It does not need to be accurate, since the actual reconstruction is done with the direct Fourier Transform.

This is, in principle, how the proof-of-concept algorithm works. Instead of reconstructing an image, it reconstructs in the starlet space. It uses the starlet transform of the dirty image to find likely non-zero components. Coordinate Descent is used to optimize single starlets. A proof-of-concept version of this algorithm was developed in python.

Although the algorithm produces super-resolved images in section \ref{results}, it is currently not known if it actually converges to the true optimum. Finding all relevant non-zero starlets is left to a greedy heuristic. There may be conditions under which it never includes relevant components. Further convergence analysis was outside the scope of the project. Also note that for this implementation, every time likely non-zero components are searched, it simply uses the non-uniform FFT for the dirty image approximation. This was done for simplicity's sake and can be improved.


\subsection{The Starlet Transform} \label{cd:starlets}

\begin{figure}[h]
	\centering
	\begin{subfigure}[b]{0.4\linewidth}
		\includegraphics[width=\linewidth]{./chapters/05.algorithms/starlets/scaling.png}
		\caption{Spline scaling function}
		\label{cd:starlets:scaling}
	\end{subfigure}
	\begin{subfigure}[b]{0.4\linewidth}
		\includegraphics[width=\linewidth]{./chapters/05.algorithms/starlets/wavelet.png}
		\caption{Wavelet function}
		\label{cd:starlets:wavelet}
	\end{subfigure}
	\caption{Scaling and wavelet function of the starlet wavelet. Source: \cite{starck2015starlet}}
	\label{cd:starlets:figure}
\end{figure}

The starlet transform is an Isotropic Undecimated Wavelet Transform (IUWT) with the starlet wavelet shown in figure \ref{cd:starlets:figure}. As such, it defines two operations: The transformation from starlet into image space which is called synthesis, and the inverse which is called decomposition. The starlet space represents an image in multiple layers at different scales, where lower layers contain smaller objects and upper layers the extended emissions. The lowest starlet layer represents the stars, while the upper layer represents the largest hydrogen clouds in the image.

\begin{equation}\label{cd:starlet:w0}
\begin{aligned}
	c_0 &= \bm{x} \star B_0 \\
	\bm{w_0} &= \bm{x} - c_0
\end{aligned}
\end{equation}

Let us look at the lowest starlet layer first, and how it is calculated from the image.
B, and x.
x - c0 removes the larger structures from the image, leaving us with the smallest in $w_0$. Does are not the starlet components, $\alpha_0$. However, we can estimate them with a shrink operation.
we can then convolve $\alpha$ with the starlet function to get back to $w_0$.  In our implementation


In this case, we use it for estimating likely non-zero $\alpha$. Figure \ref{cd:heuristic:figure} shows an example for the lowest starlet layer.

\begin{figure}[h]
	\centering
	\begin{subfigure}[b]{0.25\linewidth}
		\includegraphics[width=\linewidth]{./chapters/05.algorithms/starlets/dirty2.png}
		\caption{Dirty Image with two point sources.}
		\label{cd:heuristic:dirty}
	\end{subfigure}
	\begin{subfigure}[b]{0.25\linewidth}
		\includegraphics[width=\linewidth]{./chapters/05.algorithms/starlets/starlet0_2.png}
		\caption{Layer $w_0$ of the starlet decomposition.}
		\label{cd:heuristic:starlet}
	\end{subfigure}
	\caption{Dirty map and $w_0$ starlet layer. The right image shows the probability distribution for point sources in the dirty image.}
	\label{cd:heuristic:figure}
\end{figure}


The full decomposition is then just repeated for each intermediate layer $w_i$. \eqref{cd:starlet:decomposition}
!!!!!A trous algorithm, size of the differtent $S_i$
The last, heavily blurred $c_J$ contains the structures which were too big to represent with the largest starlets, and is the last layer of the decomposition.

\begin{equation}\label{cd:starlet:decomposition}
	\begin{split}
		c_0 &= \bm{x} \star B_0 \\
		\bm{w_0} &= \bm{x} - c_0
	\end{split}
	\qquad
	\begin{split}
		c_1 &= c_0 \star B_1 \\
		\bm{w_1} &= c_0 - c_1
	\end{split}
	\qquad \ldots \qquad
	\begin{split}
		c_{J-1} &= c_{J-2} \star B_{J-1} \\
		\bm{w_{J-1}} &= c_{J-2} - c_{J-1}
	\end{split}
	\qquad
	\begin{split}
		\bm{c_J} &= c_{J-1} \star B_J
	\end{split}
\end{equation}

The synthesis transform however is easy.

\begin{equation} \label{cd:starlet:backwards}
\bm{x} = \bm{w_0} + \bm{w_1} + \ldots + \bm{w_{J-1}} + \bm{c_J}
\end{equation}

The starlet decomposition is over-complete.

The difference between $\alpha$ and $w_i$ is not always important. For the SASIR algorithm,  for FISTA, which is how \cite{girard2015sparse} used the starlet transform for regularization, shrinkage on $w_i$ without convolution.

For FISTA, this is irrelevant, but for Coordinate descent it is important. note on the shrinkage


the original starlet people \cite{starck2015starlet} does not differentiate between $\alpha$ and $w_i$, and neither did \cite{girard2015sparse}. For the Coordinate Descent implementation it is relevant for handling the positivity constraint.

\subsubsection{Handling the positivity constraint}
As mentioned in section \ref{cd}, image reconstruction algorithms for radio astronomy typically constrain the image to be non-negative\cite{mcewen2011compressed}.


\subsection{Coordinate Descent Implementation}
We have the starlet regularization, let us put it into an algorithm. Start with the 

\begin{equation}\label{cd:starlet}
\underset{\alpha}{minimize} \: \left \| V - FD\alpha \right \|_2^2 + \lambda \left \| \alpha \right \|_1 \\
\end{equation}

Proof of concept implementation. There are many ways to improve the efficiency and the convergence speed. It is here to show  the general if it is possible of the approach and if we can truly only calculate a subset of $F^{-1}$ columns.

The objective function \eqref{cd:starlet} minimizes the starlet components $\alpha$. This objective leads again to a parabola in the one dimensional case, and we can analytically find the optimum for a single component when all others are fixed. 



There are still a few problems to solve, like how to handle the matrix product $F^{-1}D$, 
With the active set heuristic, we iterate over a limited number of starlet components at a time. 

The question remains, how the matrix product $F^{-1}D$ can be calculated efficiently. Since starlet transform is just made up of a couple of convolutions, we do not have to calculate the product $F^{-1}D$ explicitly. Convolutions in image space are multiplications in Fourier space. 
So for any starlet layer $w_i$ or $c_J$, we can pre-calculate a transform vector. 
$w_2 = F^{-1}V * (\hat{S_0}\hat{S_1} - \hat{S_0}\hat{S_1}\hat{S_2})$

How many layers are needed. starlets rise in pixels with $2^J$. Meaning if we want starlets over the whole image, the number of starlets rise logarithmically to the image dimensions.

How to iterate over the image in detail.



\subsection{Iteration scheme}
Many ways to iterate over the image. A simple scheme was used here. 

Active set heuristic, find the starlets which are 

\begin{lstlisting} 
def coordinate_descent(V_residual, x, lambda, max_iter):
	for k in range(0, max_iter):
		for i in pixels_row:
			for j in pixels_column:
				x_old = x[i, j]
				fourier_column = calculate_fourier_transform(i, j)
				fr = real(fourier_column)
				fi = imag(fourier_column)
				rr = real(V_residual)
				ri = imag(V_residual)
				
				#find apex
				a = sum(fr**2 + 2*fr*fi + fi**2)
				b = sum(fr*rr + fr*ri + fi*rr + fi*ri)
				x_new = b / a + x_old
				
				x_new = shrink(x_new, lambda)
				x[i, j] = x_new
				V_residual = V_residual - fourier_column * (x_new - x_old)
\end{lstlisting}\label{cd:implementation}

coordinate descent with active set heuristic


sub-zero pixels

\subsubsection{Non-uniform FFT approximations}
Non uniform FFT to calculate the convolution KERNELS!!


Stupid approach with line search. Could be done more efficiently by using the histogram of the starlet level.

